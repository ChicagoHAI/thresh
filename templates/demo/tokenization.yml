# We support the following tokenization options:

# - word        - Selection boundaries defined by whitespaces, enabled by default
# - char        - Selection boundaries defined by characters
# - tokenzized  - Selection boundaries defined by whitespaces and Ġ (\u0120) characters. These 
#                 are the subword token boundaries defined by GPT and RoBERTa tokenizers
tokenization: tokenized

# In our data a white space denotes a new token, and a 'Ġ' denotes the beginning of a new word.
# When rendering annotation, the whitespaces are ignored.

# For a guide on how to create a tokenized dataset, please refer to:
# https://github.com/davidheineman/nlproc.tools/blob/main/notebook_tutorials/subword_annotation.ipynb

# ========================================================================================
# ========================================================================================

template_name: demo
template_label: Tokenization Demo
edits:
  - name: edit_name
    label: "Edit Name"
    color: red
    icon: fa-magnifying-glass
    enable_input: true
    enable_output: true
